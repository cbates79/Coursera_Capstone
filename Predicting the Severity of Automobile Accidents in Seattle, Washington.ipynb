{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the Severity of Automobile Accidents in Seattle, Washington ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first week, you will discover your\n",
    "project objectives, find your dataset that you will use for this capstone project, and publish your\n",
    "dataset on GitHub.\n",
    "\n",
    "In the second week, you will build your machine\n",
    "learning solution.\n",
    "\n",
    "In the third week,\n",
    "you will finalize your model and be ready\n",
    "to submit your work.\n",
    "\n",
    "To complete capstone,\n",
    "you will be working on a case study which is to predict the severity\n",
    "of an accident.\n",
    "Now, wouldn't it be great if there were something in place that could warn you, \n",
    "given the weather and the road conditions,\n",
    "about the possibility of you getting into a car accident and how severe it would be,\n",
    "so that you would drive more carefully or even change your travel plans?\n",
    "Let's use our shared data for Seattle, Washington as an example of how to deal with the accidents data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and modules.\n",
    "import io\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import scipy\n",
    "import scipy.optimize as opt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sys\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from scipy import optimize\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes no arguments and returns an integer representing\n",
    "# the system time elapsed in seconds from a fixed instant of time.\n",
    "# This function requires the os package to be imported.\n",
    "# Specifically, it uses built-in function times() from module posix.\n",
    "def time_now():\n",
    "    return os.times()[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a global variable to store the starting time for this notebook.\n",
    "global notebook_start_time \n",
    "notebook_start_time = time_now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the time elapsed in seconds from the \n",
    "# time represented by the first parameter (start_time)\n",
    "# to the time represented by the second parameter (end_time)\n",
    "# This function requires the os package to be imported.\n",
    "def elapsed_time(start_time = notebook_start_time):\n",
    "    return time_now() - start_time   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function prints the time elapsed in seconds from the \n",
    "# time represented by the first parameter (start_time)\n",
    "# to the time represented by the second parameter (end_time)\n",
    "# This function requires the os package to be imported.\n",
    "def print_elapsed_time(start_time = notebook_start_time):\n",
    "    print(\"Elapsed time is\", elapsed_time(start_time), \"seconds.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of display options.\n",
    "list_of_display_options_fully_qualified_names = str(\\\n",
    "\"pd.options.display.chop_threshold, pd.options.display.float_format, pd.options.display.max_info_columns, pd.options.display.notebook_repr_html, \\\n",
    "pd.options.display.colheader_justify, pd.options.display.html, pd.options.display.max_info_rows, pd.options.display.pprint_nest_depth, \\\n",
    "pd.options.display.column_space, pd.options.display.large_repr, pd.options.display.max_rows, pd.options.display.precision, \\\n",
    "pd.options.display.date_dayfirst, pd.options.display.latex, pd.options.display.max_seq_items, pd.options.display.show_dimensions, \\\n",
    "pd.options.display.date_yearfirst, pd.options.display.max_categories, pd.options.display.memory_usage, pd.options.display.unicode, \\\n",
    "pd.options.display.encoding, pd.options.display.max_columns, pd.options.display.min_rows, pd.options.display.width, \\\n",
    "pd.options.display.expand_frame_repr, pd.options.display.max_colwidth, pd.options.display.multi_sparse\").split(sep=', ')\n",
    "\n",
    "# Initialize an empty list to store all the short names for display options.\n",
    "list_of_display_options_short_names = list()\n",
    "# For each fully qualified option name,\n",
    "# get the option's short name and add it to the list of short names.\n",
    "for fully_qualified_option_name in list_of_display_options_fully_qualified_names:\n",
    "    # Get short option name.\n",
    "    short_option_name = fully_qualified_option_name.split(sep='.')[-1]\n",
    "    \n",
    "    # Add short option name to list of display option short names.\n",
    "    list_of_display_options_short_names.append(short_option_name)\n",
    "\n",
    "# Define dictionary of display option settings.\n",
    "dict_of_display_option_settings_short_names=\\\n",
    "{\"max_info_columns\": 1000,\\\n",
    "\"colheader_justify\": \"right\",\\\n",
    "\"max_info_rows\": 1000000,\\\n",
    "\"column_space\": 1000,\\\n",
    "\"max_rows\": 1000000,\\\n",
    "\"precision\": 3,\\\n",
    "\"max_seq_items\": 1000000000000,\\\n",
    "\"show_dimensions\": True,\\\n",
    "\"max_categories\": 100,\\\n",
    "\"memory_usage\": True,\\\n",
    "\"max_columns\": 1000,\\\n",
    "\"max_colwidth\": 1000,\\\n",
    "\"float_format\": lambda x: '%.3f' % x}\n",
    "\n",
    "# Set pandas display options using dictionary of short names,\n",
    "# and display the options/value pairs.\n",
    "print(\"Setting display options...\")\n",
    "for key in list(dict_of_display_option_settings_short_names.keys()):\n",
    "    # Set display option.\n",
    "    pd.set_option(key, dict_of_display_option_settings_short_names[key])\n",
    "    # Print display option name and value.\n",
    "    print(key, \": \", pd.get_option(key), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute Information URL: https://www.seattle.gov/Documents/Departments/SDOT/GIS/Collisions_OD.pdf\n",
    "# Read the Collisions Data CSV file and store it as a DataFrame.\n",
    "# url=\"https://opendata.arcgis.com/datasets/5b5c745e0f1f48e7a53acec63a0022ab_0.csv\" # HTTPError at 202009151050, using local copy of .csv instead.\n",
    "# print(os.listdir(\"..\")) # Print list of contents of current working directory.\n",
    "local_path_to_csv = \"../Collisions.csv\"\n",
    "df=pd.read_csv(local_path_to_csv, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first few rows of the collisions DataFrame.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"data_wrangling\">Data Wrangling</h2>\n",
    "\n",
    "Steps for working with missing data:\n",
    "<ol>\n",
    "    <li>Identify missing data.</li>\n",
    "    <li>Deal with missing data.</li>\n",
    "    <li>Correct data format.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"identifying_missing_data\">Identifying Missing Data</h3>\n",
    "\n",
    "The metadata document that accompanied the data set indicates that certain columns have \"sentinel\" values\n",
    "that indicate an unknown or missing value. Each of these missing values will first be converted into NaN.\n",
    "Subsequently, the NaN values will be dropped from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If any row of the collisions DataFrame contains a sentinel value representing \"unknown\",\n",
    "# then replace it with NaN. \n",
    "# Sentinels for \"unknown\" are listed in the metadata document that accompanies the dataset.\n",
    "df_unknowns_converted_to_nan = df.replace(to_replace=\\\n",
    "{\"EXCEPTRSNCODE\": \" \",\\\n",
    " \"EXCEPTRSNDESC\": \"Not Enough Information, or Insufficient Location Information\",\\\n",
    " \"SEVERITYCODE\": \"0\",\\\n",
    " \"SEVERITYDESC\": \"Unknown\",\\\n",
    " \"JUNCTIONTYPE\": \"Unknown\",\\\n",
    " \"WEATHER\": \"Unknown\",\\\n",
    " \"ROADCOND\": \"Unknown\",\\\n",
    " \"LIGHTCOND\": \"Unknown\",\\\n",
    " \"SDOT_COLCODE\": float(0),\\\n",
    " \"SDOT_COLDESC\": \"NOT ENOUGH INFORMATION / NOT APPLICABLE\",\\\n",
    " \"ST_COLCODE\": \" \",\\\n",
    " \"ST_COLDESC\": \"Not stated\"},\\\n",
    "value=np.nan, inplace=False, limit=None, regex=False, method='pad')\n",
    "\n",
    "df_unknowns_converted_to_nan.replace(to_replace={\"ST_COLCODE\": \"0\", }, value=np.nan, inplace=True, limit=None, regex=False, method='pad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"deal_with_missing_data\">Deal with Missing Data</h3>\n",
    "\n",
    "<ol>\n",
    "    <li>Drop the Data\n",
    "        <ol>\n",
    "            <li>Drop entire row.</li>\n",
    "            <li>Drop entire column.</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>Replace the Data\n",
    "        <ol>\n",
    "            <li>Replace data by mean.</li>\n",
    "            <li>Replace data by frequency.</li>\n",
    "            <li>Replace data based on other functions.</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "        \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whole columns should be dropped only if most entries in the column are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the labels for the columns with missing data.\n",
    "list_of_columns_with_missing_data = list()\n",
    "\n",
    "# For each column in the collisions DataFrame,\n",
    "# if the column contains at least one NaN, \n",
    "# then add the column's label to the list.\n",
    "for column in list(df_unknowns_converted_to_nan.columns):\n",
    "    if df_unknowns_converted_to_nan[column].hasnans:\n",
    "        list_of_columns_with_missing_data.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any column from the collisions DataFrame if it satisfies at least one of the following conditions:\n",
    "# 1) more than 15% of the column's data is NaN;\n",
    "# 2) the column only contains unique identification keys, or information not useful for model building;\n",
    "# 3) the column's data is categorical but does not fit into a small (< 15) number of categories;\n",
    "# 4) information in the column is redundant because it is already represented by another column;\n",
    "# 5) it is not clear how to interpret the column's data.\n",
    "list_of_columns_to_drop = [\"ADDRTYPE\",\\\n",
    "                           \"STATUS\",\\\n",
    "                           \"OBJECTID\",\\\n",
    "                           \"INCKEY\",\\\n",
    "                           \"COLDETKEY\",\\\n",
    "                           \"REPORTNO\",\\\n",
    "                           \"INTKEY\",\\\n",
    "                           \"LOCATION\",\\\n",
    "                           \"EXCEPTRSNCODE\",\\\n",
    "                           \"EXCEPTRSNDESC\",\\\n",
    "                           \"SEVERITYDESC\",\\\n",
    "                           \"INCDATE\",\\\n",
    "                           \"INCDTTM\",\\\n",
    "                           \"JUNCTIONTYPE\",\\\n",
    "                           \"SDOT_COLCODE\",\\\n",
    "                           \"SDOT_COLDESC\",\\\n",
    "                           \"INATTENTIONIND\",\\\n",
    "                           \"UNDERINFL\",\\\n",
    "                           \"PEDROWNOTGRNT\",\\\n",
    "                           \"SDOTCOLNUM\",\\\n",
    "                           \"SPEEDING\",\\\n",
    "                           \"ST_COLCODE\",\\\n",
    "                           \"ST_COLDESC\",\\\n",
    "                           \"SEGLANEKEY\",\\\n",
    "                           \"CROSSWALKKEY\",\\\n",
    "                           \"HITPARKEDCAR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the selected columns from the DataFrame after converting unknowns to NaN.\n",
    "# Store the result in a new DataFrame.\n",
    "df_drop_columns = df_unknowns_converted_to_nan.drop(columns=list_of_columns_to_drop, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any row that contains at least one NaN.\n",
    "df_drop_columns_and_rows = df_drop_columns.dropna(axis=\"index\", how=\"any\", thresh=None, subset=None, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"correct_data_format\">Correct Data Format</h3>\n",
    "\n",
    "Ensure that each data type is appropriate for the corresponding feature.\n",
    "Cast columns of type \"object\" as type \"category\", but leave all other column types unaltered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame to store converted data types.\n",
    "df_converted = pd.DataFrame()\n",
    "\n",
    "for column in list(df_drop_columns_and_rows.columns):\n",
    "    if (df_drop_columns_and_rows[column].dtype in [np.dtype('object')]):\n",
    "        df_converted[column] = df_drop_columns_and_rows[column].astype('category')\n",
    "    # Copy all other columns to new DataFrame without changing their types.\n",
    "    else:\n",
    "        df_converted[column] = df_drop_columns_and_rows[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast columns \"INCDTTM\" to type datetime.\n",
    "    #if column in [\"INCDTTM\"]:\n",
    "    #    df_converted[column] = pd.to_datetime(df_drop_columns_and_rows[column], infer_datetime_format=True)\n",
    "    # Cast columns of type object to type category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of categorical columns.\n",
    "df_categorical = df_converted.select_dtypes(include=\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features before One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_categorical.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categorical.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_categorical[[\"COLLISIONTYPE\", \"WEATHER\", \"ROADCOND\", \"LIGHTCOND\"]]\n",
    "#features = df_categorical[[\"WEATHER\", \"ROADCOND\", \"LIGHTCOND\"]]\n",
    "#features = df_categorical[[\"COLLISIONTYPE\", \"WEATHER\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_features = list(features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SEVERITYCODE relative frequencies:\")\n",
    "print(df_categorical[\"SEVERITYCODE\"].value_counts(normalize=True, dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in list_of_features:\n",
    "    print(df_categorical.groupby(feature)[\"SEVERITYCODE\"].value_counts(normalize=True, dropna=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in list_of_features:\n",
    "    print(df_categorical.groupby(\"SEVERITYCODE\")[feature].value_counts(normalize=True, dropna=False))\n",
    "    #print(df_categorical.groupby(\"SEVERITYCODE\")[feature].value_counts(normalize=False, dropna=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a features set represented by the numerical DataFrame X_not_normalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define the labels for the target variable, SEVERITYCODE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_categorical[\"SEVERITYCODE\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Categorical Features as a One-Hot Numeric Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use one hot encoding technique to convert categorical varables to binary variables and append them to the features DataFrame "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# For each feature of the features DataFrame,\n",
    "# get dummy encoding for the feature,\n",
    "# prefix the category column labels with the feature label and a '_' separator,\n",
    "# and concatenate the one-hot encoded columns to the features DataFrame.\n",
    "for feature in list(features.columns):\n",
    "    features = pd.concat([features, pd.get_dummies(features[feature], prefix=feature, prefix_sep='_', dummy_na=False, columns=feature, sparse=False, drop_first=False)], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### DELETE BEFORE PRODUCTION CODE\n",
    "# NOTE: OneHotEncoder(*, categories='auto', drop=None, sparse=True, dtype=<class 'numpy.float64'>, handle_unknown='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder and fit it to the features of the training data.\n",
    "# OneHotEncoder will transform the data into a sparse matrix if the parameter sparse=True,\n",
    "# otherwise the output will be a 2-D array.\n",
    "start_time = time_now()\n",
    "print(\"Fitting OneHotEncoder to training data...\")\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(X_train)\n",
    "print(\"Completed in\", elapsed_time(start_time), \"seconds.\")\n",
    "# Display the categories of the encoder.\n",
    "print(encoder.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training data features using OneHotEncoder.\n",
    "start_time = time_now()\n",
    "print()\n",
    "X_train_one_hot_encoded = encoder.transform(X_train)\n",
    "print(\"Completed in\", elapsed_time(start_time), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train_one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_one_hot_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data features using the same instance of the OneHotEncoder\n",
    "# that was applied to the training data features.\n",
    "start_time = time_now()\n",
    "print()\n",
    "X_test_one_hot_encoded = encoder.transform(X_test)\n",
    "print(\"Completed in\", elapsed_time(start_time), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_test_one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_one_hot_encoded.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# scipy.sparse.csr.csr_matrix : compressed sparse row matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize the data by transforming it so that it is compatible\n",
    "with the machine learning estimators we use in this notebook.\n",
    "We use special care with sparse matrix data so as to not destroy the\n",
    "structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a StandardScaler applicable to sparse CSR or CSC matrix data.\n",
    "# Pass with_mean=False to the constructor to avoid breaking the sparsity structure\n",
    "# of the data.\n",
    "# To avoid unnecessary memory copies, use CSR or CSC representation upstream.\n",
    "scaler = StandardScaler(with_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the sparse one-hot encoded training data,\n",
    "# and store the transformed data.\n",
    "start_time = time_now()\n",
    "X_train_transformed = scaler.fit_transform(X_train_one_hot_encoded)\n",
    "print_elapsed_time(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the sparse one-hot encoded test data\n",
    "# using the same StandardScaler instance that was used to\n",
    "# transform the sparse, one-hot encoded training data.\n",
    "start_time = time_now()\n",
    "X_test_transformed = scaler.transform(X_test_one_hot_encoded)\n",
    "print_elapsed_time(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the normalized data and target labels into a training test and a test set.\n",
    "We use the training set to build an accurate model.\n",
    "Afterwards, we use the test set to report the accuracy of the model.\n",
    "\n",
    "We apply the following algorithms to produce various kinds of models.\n",
    "- K Nearest Neighbor(KNN)\n",
    "- Decision Tree\n",
    "- Support Vector Machine\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a K-Nearest Neighbors (KNN) Model\n",
    "For each integer $1 \\le k \\le 20$, we build a KNN classifier with $k$ neighbors and compute the Jaccard score\n",
    "for the classifier. The best value of $k$ corresponds to classifier with maximum Jaccard score.\n",
    "The upper bound of $50$ was chosen as a matter of convenience, since each KNN classifier requires significant\n",
    "system resources to construct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy of KNN for different numbers of neighbors k, \n",
    "# and select the value of k that maximizes Jaccard score.\n",
    "Ks = 21\n",
    "mean_acc = np.zeros(Ks - 1)\n",
    "std_acc = np.zeros(Ks - 1)\n",
    "time_on_enter_for_loop = time_now()\n",
    "for n in range(1, Ks):\n",
    "    single_pass_start_time = time_now()\n",
    "    print(\"For number of neighbors k = \", n, \", \", sep=\"\", end=\"\")\n",
    "    # Train Model and Predict\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors = n, weights=\"uniform\", algorithm=\"brute\", leaf_size=30, p=1, metric=\"minkowski\", metric_params=None, n_jobs=-1)\n",
    "    knn_clf.fit(X_train_transformed, y_train)\n",
    "    y_knn_predictions = knn_clf.predict(X_test_transformed)\n",
    "    mean_acc[n - 1] = accuracy_score(y_test, y_knn_predictions)\n",
    "    std_acc[n - 1] = np.std(y_test == y_knn_predictions) / np.sqrt(Ks)\n",
    "    print(\"accuracy = \", mean_acc[n - 1], sep='', end='')\n",
    "    single_pass_end_time = time_now()\n",
    "    single_pass_elapsed_time = single_pass_end_time - single_pass_start_time\n",
    "    print(\" in\", single_pass_elapsed_time, \"seconds.\")\n",
    "\n",
    "print()\n",
    "print(\"Elapsed time to find optimum KNN classifier:\", elapsed_time(time_on_enter_for_loop), \"seconds.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# For efficiency, store a copy of the best KNeighborsClassifer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model accuracy for different number of neighbors k\n",
    "plt.plot(range(1, Ks), mean_acc, 'g')\n",
    "plt.fill_between(range(1, Ks), mean_acc - 1 * std_acc, mean_acc + 1 * std_acc, alpha=0.10)\n",
    "plt.legend(('Accuracy ', '+/- 3 std. dev.'))\n",
    "plt.ylabel('Accuracy ')\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report best accuracy and corresponding value for k.\n",
    "print( \"The best accuracy was\", mean_acc.max(), \"with a number of neighbors k =\", mean_acc.argmax()+1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the most accurate KNN model by using a value of k that maximizes the Jaccard score.\n",
    "k_best = mean_acc.argmax() + 1\n",
    "print(\"Building KNeighborsClassifier with k =\", k_best, \" neighbors...\")\n",
    "start_time = time_now()\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = k_best, weights=\"uniform\", algorithm=\"brute\", leaf_size=30, p=1, metric=\"minkowski\", metric_params=None, n_jobs=-1)\n",
    "knn_clf.fit(X_train_transformed, y_train)\n",
    "print(\"Completed in\", elapsed_time(start_time), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the K Nearest Neighbor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a decision tree model from the training data previously generated.\n",
    "start_time = time_now()\n",
    "decision_tree = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "decision_tree.fit(X_train_transformed, y_train)\n",
    "print(\"Built Decision Tree Model in\", elapsed_time(start_time), \"seconds.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a support vector machine model from the training data previously generated.\n",
    "start_time = time_now()\n",
    "svm_clf = svm.SVC(kernel='rbf', gamma='auto')\n",
    "svm_clf.fit(X_train_transformed, y_train)\n",
    "print(\"Built Support Vector Machine Model in\", elapsed_time(start_time), \"seconds.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a logistic regression model from the training data previously generated.\n",
    "start_time = time_now()\n",
    "lr = LogisticRegression(C=0.01, solver='liblinear').fit(X_train_transformed, y_train)\n",
    "print(\"Built Logistic Regression Model in\", elapsed_time(start_time), \"seconds.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Various Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time_now()\n",
    "# Apply KNN to the test set, generate predictions for KNN.\n",
    "print(\"Running command: y_knn_predictions = knn_clf.predict(X_test_transformed)\")\n",
    "y_knn_predictions = knn_clf.predict(X_test_transformed)\n",
    "print(\"Completed in\", elapsed_time(start_time), \"seconds.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_knn_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_knn_predictions).value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Decision Tree to the test set, generate predictions for Decision Tree.\n",
    "print(\"Running command: y_tree_predictions = decision_tree.predict(X_test_transformed)\")\n",
    "start_time = time_now()\n",
    "y_tree_predictions = decision_tree.predict(X_test_transformed)\n",
    "print(\"Completed in\", elapsed_time(start_time), \"seconds\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_tree_predictions).value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SVM to the test set, generate predictions for SVM.\n",
    "print(\"Running command: y_svm_predictions = clf.predict(X_test)\")\n",
    "start_time = time_now()\n",
    "y_svm_predictions = svm_clf.predict(X_test_transformed)\n",
    "print(\"Completed in\", elapsed_time(start_time), \"seconds.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_svm_predictions).value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Logistic Regression to the test set, generate predictions and probabilities for Logistic Regression.\n",
    "print(\"Running command: y_lr_predictions = lr.predict(X_test_transformed)\")\n",
    "start_time = time_now()\n",
    "y_lr_predictions = lr.predict(X_test_transformed)\n",
    "print(\"Completed in\", elapsed_time(start_time), \"seconds.\")\n",
    "print()\n",
    "\n",
    "print(\"Running command: y_lr_probabilities = lr.predict_proba(X_test_transformed)\")\n",
    "start_time = time_now()\n",
    "y_lr_probabilities = lr.predict_proba(X_test_transformed)\n",
    "print(\"Completed in\", elapsed_time(start_time), \"seconds.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_lr_predictions).value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create and fit a label encoder for the target labels.\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_test)\n",
    "# Transform the labels of the target test set into dummy labels.\n",
    "y_test_lr_dummies = le.transform(y_test)\n",
    "y_lr_predictions_dummies = le.transform(y_lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numpy arrays to store the results of tests of the various algorithms.\n",
    "# index = 0 => KNN score\n",
    "# index = 1 => Decision Tree\n",
    "# index = 2 => SVM\n",
    "# index = 3 => Logistic Regression\n",
    "jaccard = np.zeros((4,4))\n",
    "f1 = np.zeros((4,4))\n",
    "logloss = np.zeros((4,4))\n",
    "logloss[0] = np.nan\n",
    "logloss[1] = np.nan\n",
    "logloss[2] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For KNN model, compute Jaccard score.\n",
    "jaccard[0] = jaccard_score(y_test, y_knn_predictions, labels=[\"1\", \"2\", \"2b\", \"3\"], average=None)\n",
    "print(\"KNN Jaccard score is\", jaccard[0,:])\n",
    "# For KNN model, compute F1-score.\n",
    "f1[0] = f1_score(y_test, y_knn_predictions, average=None)\n",
    "print(\"KNN F1-score is\", f1[0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Decision Tree model, compute Jaccard score.\n",
    "jaccard[1] = jaccard_score(y_test, y_tree_predictions, labels=[\"1\", \"2\", \"2b\", \"3\"], average=None)\n",
    "print(\"Decision Tree Jaccard score is: \", jaccard[1])\n",
    "# For Decision Tree model, compute F1-score.\n",
    "f1[1] = f1_score(y_test, y_tree_predictions, average=None)\n",
    "print(\"Decision Tree F1-score is: \", f1[1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SVM algorithm, compute Jaccard score.\n",
    "jaccard[2] = jaccard_score(y_test, y_svm_predictions, labels=[\"1\", \"2\", \"2b\", \"3\"], average=None)\n",
    "print(\"SVM Jaccard score is\", jaccard[2])\n",
    "# For SVM algorithm, compute F1-score.\n",
    "f1[2] = f1_score(y_test, y_svm_predictions, average=None)\n",
    "print(\"SVM F1-score is\", f1[2])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For logistic regression algorithm, compute Jaccard score.\n",
    "jaccard[3] = jaccard_score(y_test, y_lr_predictions, labels=[\"1\", \"2\", \"2b\", \"3\"], average=None)\n",
    "print(\"Logistic Regression Jaccard similarity score is\", jaccard[3])\n",
    "# For logistic regression algorithm, compute F1-score.\n",
    "f1[3] = f1_score(y_test, y_lr_predictions, average=None)\n",
    "print(\"Logistic Regression F1-score is\", f1[3])\n",
    "# For logistic regression algorithm, compute log loss.\n",
    "logloss[3] = log_loss(y_test, y_lr_probabilities)\n",
    "print(\"Logistic Regression log loss is\", logloss[3])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "report_df = pd.DataFrame(data={'Algorithm':['KNN', 'Decision Tree', 'SVM', 'LogisticRegression'],\n",
    "                               'Jaccard':jaccard,\n",
    "                               'F1-score':f1,\n",
    "                               'LogLoss':logloss})\n",
    "\n",
    "report_df[['Algorithm', 'Jaccard', 'F1-score', 'LogLoss']].style.hide_index()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###  DELETE BEFORE PRODUCTION CODE\n",
    "# NOTE: classification_report(y_true, y_pred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "# NOTE: confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report and Confusion matrix for KNN\n",
    "print(classification_report(y_test, y_knn_predictions, labels=[\"1\", \"2\", \"2b\", \"3\"], target_names=[\"1\", \"2\", \"2b\", \"3\"]))\n",
    "print(confusion_matrix(y_test, y_knn_predictions, labels=[\"1\", \"2\", \"2b\", \"3\"], normalize=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report and Confusion matrix for Decision Tree\n",
    "print(classification_report(y_test, y_tree_predictions, labels=[\"1\", \"2\", \"2b\", \"3\"], target_names=[\"1\", \"2\", \"2b\", \"3\"]))\n",
    "print(confusion_matrix(y_test, y_tree_predictions, labels=[\"1\", \"2\", \"2b\", \"3\"], normalize=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report and Confusion matrix for SVM\n",
    "print(classification_report(y_test, y_svm_predictions, labels=[\"1\", \"2\", \"2b\", \"3\"], target_names=[\"1\", \"2\", \"2b\", \"3\"]))\n",
    "print(confusion_matrix(y_test, y_svm_predictions, labels=[\"1\", \"2\", \"2b\", \"3\"], normalize=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report and Confusion matrix for Logisitic Regression\n",
    "print(classification_report(y_test, y_lr_predictions, labels=[\"1\", \"2\", \"2b\", \"3\"], target_names=[\"1\", \"2\", \"2b\", \"3\"]))\n",
    "print(confusion_matrix(y_test, y_lr_predictions, labels=[\"1\", \"2\", \"2b\", \"3\"], normalize=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Notebook total elapsed time:\", elapsed_time(), \"seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
