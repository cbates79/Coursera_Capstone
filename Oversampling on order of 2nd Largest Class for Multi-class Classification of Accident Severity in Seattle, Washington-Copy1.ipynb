{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"oversampling_on_order_of_2nd_largest_class_for_multiclass_classification_of_accidents\">Oversampling on order of 2nd Largest Class for Multi-class Classification of Accident Severity in Seattle, Washington<\\h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and modules.\n",
    "import io\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import scipy\n",
    "import scipy.optimize as opt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sys\n",
    "import timeit\n",
    "import warnings\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from scipy import optimize\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import utils\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from timeit import default_timer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning,\n",
    "                        module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the starting time for this notebook. \n",
    "notebook_start_time = default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the time elapsed in seconds from the \n",
    "# time represented by the first parameter (start_time)\n",
    "# to the time represented by the second parameter (end_time)\n",
    "# This function requires the os package to be imported.\n",
    "def elapsed_time(start_time = notebook_start_time):\n",
    "    return default_timer() - start_time   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function prints the time elapsed in seconds from the \n",
    "# time represented by the first parameter (start_time)\n",
    "# to the time represented by the second parameter (end_time)\n",
    "# This function requires the os package to be imported.\n",
    "def print_elapsed_time(start_time = notebook_start_time):\n",
    "    print(\"Elapsed time is\", elapsed_time(start_time), \"seconds.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting display options...\n",
      "max_info_columns: 1000\n",
      "colheader_justify: right\n",
      "max_info_rows: 1000000\n",
      "column_space: 1000\n",
      "max_rows: 1000000\n",
      "precision: 9\n",
      "max_seq_items: 1000000000000\n",
      "show_dimensions: True\n",
      "max_categories: 100\n",
      "memory_usage: True\n",
      "max_columns: 1000\n",
      "max_colwidth: 1000\n",
      "float_format: <function <lambda> at 0x7f3b85cbff70>\n"
     ]
    }
   ],
   "source": [
    "# Create a list of display options.\n",
    "list_of_display_options_fully_qualified_names = str(\\\n",
    "\"pd.options.display.chop_threshold, pd.options.display.float_format, pd.options.display.max_info_columns, pd.options.display.notebook_repr_html, \\\n",
    "pd.options.display.colheader_justify, pd.options.display.html, pd.options.display.max_info_rows, pd.options.display.pprint_nest_depth, \\\n",
    "pd.options.display.column_space, pd.options.display.large_repr, pd.options.display.max_rows, pd.options.display.precision, \\\n",
    "pd.options.display.date_dayfirst, pd.options.display.latex, pd.options.display.max_seq_items, pd.options.display.show_dimensions, \\\n",
    "pd.options.display.date_yearfirst, pd.options.display.max_categories, pd.options.display.memory_usage, pd.options.display.unicode, \\\n",
    "pd.options.display.encoding, pd.options.display.max_columns, pd.options.display.min_rows, pd.options.display.width, \\\n",
    "pd.options.display.expand_frame_repr, pd.options.display.max_colwidth, pd.options.display.multi_sparse\").split(sep=', ')\n",
    "\n",
    "# Initialize an empty list to store all the short names for display options.\n",
    "list_of_display_options_short_names = list()\n",
    "# For each fully qualified option name,\n",
    "# get the option's short name and add it to the list of short names.\n",
    "for fully_qualified_option_name in list_of_display_options_fully_qualified_names:\n",
    "    # Get short option name.\n",
    "    short_option_name = fully_qualified_option_name.split(sep='.')[-1]\n",
    "    \n",
    "    # Add short option name to list of display option short names.\n",
    "    list_of_display_options_short_names.append(short_option_name)\n",
    "\n",
    "# Define dictionary of display option settings.\n",
    "dict_of_display_option_settings_short_names=\\\n",
    "{\"max_info_columns\": 1000,\\\n",
    "\"colheader_justify\": \"right\",\\\n",
    "\"max_info_rows\": 1000000,\\\n",
    "\"column_space\": 1000,\\\n",
    "\"max_rows\": 1000000,\\\n",
    "\"precision\": 9,\\\n",
    "\"max_seq_items\": 1000000000000,\\\n",
    "\"show_dimensions\": True,\\\n",
    "\"max_categories\": 100,\\\n",
    "\"memory_usage\": True,\\\n",
    "\"max_columns\": 1000,\\\n",
    "\"max_colwidth\": 1000,\\\n",
    "\"float_format\": lambda x: '%.9f' % x}\n",
    "\n",
    "# Set pandas display options using dictionary of short names,\n",
    "# and display the options/value pairs.\n",
    "print(\"Setting display options...\")\n",
    "for key in list(dict_of_display_option_settings_short_names.keys()):\n",
    "    # Set display option.\n",
    "    pd.set_option(key, dict_of_display_option_settings_short_names[key])\n",
    "    # Print display option name and value.\n",
    "    print(key, \": \", pd.get_option(key), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17609238\n"
     ]
    }
   ],
   "source": [
    "# Set seed for random number generator.\n",
    "# seed = np.int(os.times()[4]) # Use this line for better pseudo-random behavior.\n",
    "seed = np.int(os.times()[4])\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute Information URL: https://www.seattle.gov/Documents/Departments/SDOT/GIS/Collisions_OD.pdf\n",
    "# Read the Collisions Data CSV file and store it as a DataFrame.\n",
    "# url=\"https://opendata.arcgis.com/datasets/5b5c745e0f1f48e7a53acec63a0022ab_0.csv\" # HTTPError at 202009151050, using local copy of .csv instead.\n",
    "# print(os.listdir()) # Print list of contents of current working irectory.\n",
    "local_path_to_csv = '~/IBM Data Science Professional Certificate Course/Course 9 - Applied Data Science Capstone/projects/Collisions.csv'\n",
    "df=pd.read_csv(local_path_to_csv, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>INCKEY</th>\n",
       "      <th>COLDETKEY</th>\n",
       "      <th>REPORTNO</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ADDRTYPE</th>\n",
       "      <th>INTKEY</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>EXCEPTRSNCODE</th>\n",
       "      <th>EXCEPTRSNDESC</th>\n",
       "      <th>SEVERITYCODE</th>\n",
       "      <th>SEVERITYDESC</th>\n",
       "      <th>COLLISIONTYPE</th>\n",
       "      <th>PERSONCOUNT</th>\n",
       "      <th>PEDCOUNT</th>\n",
       "      <th>PEDCYLCOUNT</th>\n",
       "      <th>VEHCOUNT</th>\n",
       "      <th>INJURIES</th>\n",
       "      <th>SERIOUSINJURIES</th>\n",
       "      <th>FATALITIES</th>\n",
       "      <th>INCDATE</th>\n",
       "      <th>INCDTTM</th>\n",
       "      <th>JUNCTIONTYPE</th>\n",
       "      <th>SDOT_COLCODE</th>\n",
       "      <th>SDOT_COLDESC</th>\n",
       "      <th>INATTENTIONIND</th>\n",
       "      <th>UNDERINFL</th>\n",
       "      <th>WEATHER</th>\n",
       "      <th>ROADCOND</th>\n",
       "      <th>LIGHTCOND</th>\n",
       "      <th>PEDROWNOTGRNT</th>\n",
       "      <th>SDOTCOLNUM</th>\n",
       "      <th>SPEEDING</th>\n",
       "      <th>ST_COLCODE</th>\n",
       "      <th>ST_COLDESC</th>\n",
       "      <th>SEGLANEKEY</th>\n",
       "      <th>CROSSWALKKEY</th>\n",
       "      <th>HITPARKEDCAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.320757054</td>\n",
       "      <td>47.609407946</td>\n",
       "      <td>1</td>\n",
       "      <td>328476</td>\n",
       "      <td>329976</td>\n",
       "      <td>EA08706</td>\n",
       "      <td>Matched</td>\n",
       "      <td>Block</td>\n",
       "      <td>nan</td>\n",
       "      <td>BROADWAY BETWEEN E COLUMBIA ST AND BOYLSTON AVE</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Property Damage Only Collision</td>\n",
       "      <td>Sideswipe</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020/01/22 00:00:00+00</td>\n",
       "      <td>1/22/2020 3:21:00 PM</td>\n",
       "      <td>Mid-Block (not related to intersection)</td>\n",
       "      <td>11.000000000</td>\n",
       "      <td>MOTOR VEHICLE STRUCK MOTOR VEHICLE, FRONT END AT ANGLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Raining</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Dark - Street Lights On</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>From same direction - both going straight - both moving - sideswipe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.319560827</td>\n",
       "      <td>47.662220664</td>\n",
       "      <td>2</td>\n",
       "      <td>328142</td>\n",
       "      <td>329642</td>\n",
       "      <td>EA06882</td>\n",
       "      <td>Matched</td>\n",
       "      <td>Block</td>\n",
       "      <td>nan</td>\n",
       "      <td>8TH AVE NE BETWEEN NE 45TH E ST AND NE 47TH ST</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Property Damage Only Collision</td>\n",
       "      <td>Parked Car</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020/01/07 00:00:00+00</td>\n",
       "      <td>1/7/2020 8:00:00 AM</td>\n",
       "      <td>Mid-Block (not related to intersection)</td>\n",
       "      <td>15.000000000</td>\n",
       "      <td>MOTOR VEHICLE STRUCK MOTOR VEHICLE, RIGHT SIDE SIDESWIPE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>One parked--one moving</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.327524508</td>\n",
       "      <td>47.604393273</td>\n",
       "      <td>3</td>\n",
       "      <td>20700</td>\n",
       "      <td>20700</td>\n",
       "      <td>1181833</td>\n",
       "      <td>Unmatched</td>\n",
       "      <td>Block</td>\n",
       "      <td>nan</td>\n",
       "      <td>JAMES ST BETWEEN 6TH AVE AND 7TH AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2004/01/30 00:00:00+00</td>\n",
       "      <td>1/30/2004</td>\n",
       "      <td>Mid-Block (but intersection related)</td>\n",
       "      <td>11.000000000</td>\n",
       "      <td>MOTOR VEHICLE STRUCK MOTOR VEHICLE, FRONT END AT ANGLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4030032.000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.327524934</td>\n",
       "      <td>47.708621579</td>\n",
       "      <td>4</td>\n",
       "      <td>332126</td>\n",
       "      <td>333626</td>\n",
       "      <td>M16001640</td>\n",
       "      <td>Unmatched</td>\n",
       "      <td>Block</td>\n",
       "      <td>nan</td>\n",
       "      <td>NE NORTHGATE WAY BETWEEN 1ST AVE NE AND NE NORTHGATE DR</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016/01/23 00:00:00+00</td>\n",
       "      <td>1/23/2016</td>\n",
       "      <td>Mid-Block (not related to intersection)</td>\n",
       "      <td>11.000000000</td>\n",
       "      <td>MOTOR VEHICLE STRUCK MOTOR VEHICLE, FRONT END AT ANGLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.292120049</td>\n",
       "      <td>47.559009080</td>\n",
       "      <td>5</td>\n",
       "      <td>328238</td>\n",
       "      <td>329738</td>\n",
       "      <td>3857118</td>\n",
       "      <td>Unmatched</td>\n",
       "      <td>Block</td>\n",
       "      <td>nan</td>\n",
       "      <td>M L KING JR ER WAY S BETWEEN S ANGELINE ST AND S EDMUNDS ST</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020/01/26 00:00:00+00</td>\n",
       "      <td>1/26/2020</td>\n",
       "      <td>Mid-Block (not related to intersection)</td>\n",
       "      <td>28.000000000</td>\n",
       "      <td>MOTOR VEHICLE RAN OFF ROAD - HIT FIXED OBJECT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               X            Y  OBJECTID  INCKEY  COLDETKEY   REPORTNO  \\\n",
       "0 -122.320757054 47.609407946         1  328476     329976    EA08706   \n",
       "1 -122.319560827 47.662220664         2  328142     329642    EA06882   \n",
       "2 -122.327524508 47.604393273         3   20700      20700    1181833   \n",
       "3 -122.327524934 47.708621579         4  332126     333626  M16001640   \n",
       "4 -122.292120049 47.559009080         5  328238     329738    3857118   \n",
       "\n",
       "      STATUS ADDRTYPE  INTKEY  \\\n",
       "0    Matched    Block     nan   \n",
       "1    Matched    Block     nan   \n",
       "2  Unmatched    Block     nan   \n",
       "3  Unmatched    Block     nan   \n",
       "4  Unmatched    Block     nan   \n",
       "\n",
       "                                                      LOCATION EXCEPTRSNCODE  \\\n",
       "0              BROADWAY BETWEEN E COLUMBIA ST AND BOYLSTON AVE                 \n",
       "1               8TH AVE NE BETWEEN NE 45TH E ST AND NE 47TH ST                 \n",
       "2                         JAMES ST BETWEEN 6TH AVE AND 7TH AVE           NaN   \n",
       "3      NE NORTHGATE WAY BETWEEN 1ST AVE NE AND NE NORTHGATE DR                 \n",
       "4  M L KING JR ER WAY S BETWEEN S ANGELINE ST AND S EDMUNDS ST                 \n",
       "\n",
       "  EXCEPTRSNDESC SEVERITYCODE                    SEVERITYDESC COLLISIONTYPE  \\\n",
       "0           NaN            1  Property Damage Only Collision     Sideswipe   \n",
       "1           NaN            1  Property Damage Only Collision    Parked Car   \n",
       "2           NaN            0                         Unknown           NaN   \n",
       "3           NaN            0                         Unknown           NaN   \n",
       "4           NaN            0                         Unknown           NaN   \n",
       "\n",
       "   PERSONCOUNT  PEDCOUNT  PEDCYLCOUNT  VEHCOUNT  INJURIES  SERIOUSINJURIES  \\\n",
       "0            2         0            0         2         0                0   \n",
       "1            2         0            0         2         0                0   \n",
       "2            0         0            0         0         0                0   \n",
       "3            0         0            0         0         0                0   \n",
       "4            0         0            0         0         0                0   \n",
       "\n",
       "   FATALITIES                 INCDATE               INCDTTM  \\\n",
       "0           0  2020/01/22 00:00:00+00  1/22/2020 3:21:00 PM   \n",
       "1           0  2020/01/07 00:00:00+00   1/7/2020 8:00:00 AM   \n",
       "2           0  2004/01/30 00:00:00+00             1/30/2004   \n",
       "3           0  2016/01/23 00:00:00+00             1/23/2016   \n",
       "4           0  2020/01/26 00:00:00+00             1/26/2020   \n",
       "\n",
       "                              JUNCTIONTYPE  SDOT_COLCODE  \\\n",
       "0  Mid-Block (not related to intersection)  11.000000000   \n",
       "1  Mid-Block (not related to intersection)  15.000000000   \n",
       "2     Mid-Block (but intersection related)  11.000000000   \n",
       "3  Mid-Block (not related to intersection)  11.000000000   \n",
       "4  Mid-Block (not related to intersection)  28.000000000   \n",
       "\n",
       "                                               SDOT_COLDESC INATTENTIONIND  \\\n",
       "0    MOTOR VEHICLE STRUCK MOTOR VEHICLE, FRONT END AT ANGLE            NaN   \n",
       "1  MOTOR VEHICLE STRUCK MOTOR VEHICLE, RIGHT SIDE SIDESWIPE            NaN   \n",
       "2    MOTOR VEHICLE STRUCK MOTOR VEHICLE, FRONT END AT ANGLE            NaN   \n",
       "3    MOTOR VEHICLE STRUCK MOTOR VEHICLE, FRONT END AT ANGLE            NaN   \n",
       "4             MOTOR VEHICLE RAN OFF ROAD - HIT FIXED OBJECT            NaN   \n",
       "\n",
       "  UNDERINFL  WEATHER ROADCOND                LIGHTCOND PEDROWNOTGRNT  \\\n",
       "0         N  Raining      Wet  Dark - Street Lights On           NaN   \n",
       "1         N    Clear      Dry                 Daylight           NaN   \n",
       "2       NaN      NaN      NaN                      NaN           NaN   \n",
       "3       NaN      NaN      NaN                      NaN           NaN   \n",
       "4       NaN      NaN      NaN                      NaN           NaN   \n",
       "\n",
       "         SDOTCOLNUM SPEEDING ST_COLCODE  \\\n",
       "0               nan      NaN         11   \n",
       "1               nan      NaN         32   \n",
       "2 4030032.000000000      NaN        NaN   \n",
       "3               nan      NaN              \n",
       "4               nan      NaN              \n",
       "\n",
       "                                                            ST_COLDESC  \\\n",
       "0  From same direction - both going straight - both moving - sideswipe   \n",
       "1                                               One parked--one moving   \n",
       "2                                                                  NaN   \n",
       "3                                                                  NaN   \n",
       "4                                                                  NaN   \n",
       "\n",
       "   SEGLANEKEY  CROSSWALKKEY HITPARKEDCAR  \n",
       "0           0             0            N  \n",
       "1           0             0            Y  \n",
       "2           0             0            N  \n",
       "3           0             0            N  \n",
       "4           0             0            N  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first few rows of the collisions DataFrame.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221389 entries, 0 to 221388\n",
      "Data columns (total 40 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   X                213918 non-null  float64\n",
      " 1   Y                213918 non-null  float64\n",
      " 2   OBJECTID         221389 non-null  int64  \n",
      " 3   INCKEY           221389 non-null  int64  \n",
      " 4   COLDETKEY        221389 non-null  int64  \n",
      " 5   REPORTNO         221389 non-null  object \n",
      " 6   STATUS           221389 non-null  object \n",
      " 7   ADDRTYPE         217677 non-null  object \n",
      " 8   INTKEY           71884 non-null   float64\n",
      " 9   LOCATION         216801 non-null  object \n",
      " 10  EXCEPTRSNCODE    100986 non-null  object \n",
      " 11  EXCEPTRSNDESC    11779 non-null   object \n",
      " 12  SEVERITYCODE     221388 non-null  object \n",
      " 13  SEVERITYDESC     221389 non-null  object \n",
      " 14  COLLISIONTYPE    195159 non-null  object \n",
      " 15  PERSONCOUNT      221389 non-null  int64  \n",
      " 16  PEDCOUNT         221389 non-null  int64  \n",
      " 17  PEDCYLCOUNT      221389 non-null  int64  \n",
      " 18  VEHCOUNT         221389 non-null  int64  \n",
      " 19  INJURIES         221389 non-null  int64  \n",
      " 20  SERIOUSINJURIES  221389 non-null  int64  \n",
      " 21  FATALITIES       221389 non-null  int64  \n",
      " 22  INCDATE          221389 non-null  object \n",
      " 23  INCDTTM          221389 non-null  object \n",
      " 24  JUNCTIONTYPE     209417 non-null  object \n",
      " 25  SDOT_COLCODE     221388 non-null  float64\n",
      " 26  SDOT_COLDESC     221388 non-null  object \n",
      " 27  INATTENTIONIND   30188 non-null   object \n",
      " 28  UNDERINFL        195179 non-null  object \n",
      " 29  WEATHER          194969 non-null  object \n",
      " 30  ROADCOND         195050 non-null  object \n",
      " 31  LIGHTCOND        194880 non-null  object \n",
      " 32  PEDROWNOTGRNT    5192 non-null    object \n",
      " 33  SDOTCOLNUM       127205 non-null  float64\n",
      " 34  SPEEDING         9928 non-null    object \n",
      " 35  ST_COLCODE       211976 non-null  object \n",
      " 36  ST_COLDESC       195159 non-null  object \n",
      " 37  SEGLANEKEY       221389 non-null  int64  \n",
      " 38  CROSSWALKKEY     221389 non-null  int64  \n",
      " 39  HITPARKEDCAR     221389 non-null  object \n",
      "dtypes: float64(5), int64(12), object(23)\n",
      "memory usage: 67.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 9.846784632012714 seconds.\n"
     ]
    }
   ],
   "source": [
    "print_elapsed_time(notebook_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"data_wrangling\">Data Wrangling</h2>\n",
    "\n",
    "Steps for working with missing data:\n",
    "<ol>\n",
    "    <li>Identify missing data.</li>\n",
    "    <li>Deal with missing data.</li>\n",
    "    <li>Correct data format.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"identifying_missing_data\">Identifying Missing Data</h3>\n",
    "\n",
    "The metadata document that accompanied the data set indicates that certain columns have \"sentinel\" values\n",
    "that indicate an unknown or missing value. Each of these missing values will first be converted into NaN.\n",
    "Subsequently, the NaN values will be dropped from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If any row of the collisions DataFrame contains a sentinel value representing \"unknown\",\n",
    "# then replace it with NaN. \n",
    "# Sentinels for \"unknown\" are listed in the metadata document that accompanies the dataset.\n",
    "df_unknowns_converted_to_nan = df.replace(to_replace=\\\n",
    "{\"EXCEPTRSNCODE\": \" \",\\\n",
    " \"EXCEPTRSNDESC\": \"Not Enough Information, or Insufficient Location Information\",\\\n",
    " \"SEVERITYCODE\": \"0\",\\\n",
    " \"SEVERITYDESC\": \"Unknown\",\\\n",
    " \"JUNCTIONTYPE\": \"Unknown\",\\\n",
    " \"WEATHER\": \"Unknown\",\\\n",
    " \"ROADCOND\": \"Unknown\",\\\n",
    " \"LIGHTCOND\": \"Unknown\",\\\n",
    " \"SDOT_COLCODE\": float(0),\\\n",
    " \"SDOT_COLDESC\": \"NOT ENOUGH INFORMATION / NOT APPLICABLE\",\\\n",
    " \"ST_COLCODE\": \" \",\\\n",
    " \"ST_COLDESC\": \"Not stated\"},\\\n",
    "value=np.nan, inplace=False, limit=None, regex=False, method='pad')\n",
    "\n",
    "df_unknowns_converted_to_nan.replace(to_replace={\"ST_COLCODE\": \"0\", }, value=np.nan, inplace=True, limit=None, regex=False, method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 17.06303348997608 seconds.\n"
     ]
    }
   ],
   "source": [
    "print_elapsed_time(notebook_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"deal_with_missing_data\">Deal with Missing Data</h3>\n",
    "\n",
    "<ol>\n",
    "    <li>Drop the Data\n",
    "        <ol>\n",
    "            <li>Drop entire row.</li>\n",
    "            <li>Drop entire column.</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>Replace the Data\n",
    "        <ol>\n",
    "            <li>Replace data by mean.</li>\n",
    "            <li>Replace data by frequency.</li>\n",
    "            <li>Replace data based on other functions.</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "        \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whole columns should be dropped only if most entries in the column are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y', 'OBJECTID', 'INCKEY', 'COLDETKEY', 'REPORTNO', 'STATUS', 'ADDRTYPE', 'INTKEY', 'LOCATION', 'EXCEPTRSNCODE', 'EXCEPTRSNDESC', 'SEVERITYCODE', 'SEVERITYDESC', 'COLLISIONTYPE', 'PERSONCOUNT', 'PEDCOUNT', 'PEDCYLCOUNT', 'VEHCOUNT', 'INJURIES', 'SERIOUSINJURIES', 'FATALITIES', 'INCDATE', 'INCDTTM', 'JUNCTIONTYPE', 'SDOT_COLCODE', 'SDOT_COLDESC', 'INATTENTIONIND', 'UNDERINFL', 'WEATHER', 'ROADCOND', 'LIGHTCOND', 'PEDROWNOTGRNT', 'SDOTCOLNUM', 'SPEEDING', 'ST_COLCODE', 'ST_COLDESC', 'SEGLANEKEY', 'CROSSWALKKEY', 'HITPARKEDCAR']\n"
     ]
    }
   ],
   "source": [
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any column from the collisions DataFrame if it satisfies at least one of the following conditions:\n",
    "# 1) more than 15% of the column's data is NaN;\n",
    "# 2) the column only contains unique identification keys, or information not useful for model building;\n",
    "# 3) the column's data is categorical but does not fit into a small (< 15) number of categories;\n",
    "# 4) information in the column is redundant because it is already represented by another column;\n",
    "# 5) it is not clear how to interpret the column's data.\n",
    "list_of_columns_to_drop = [\"ADDRTYPE\",\\\n",
    "                           \"STATUS\",\\\n",
    "                           \"OBJECTID\",\\\n",
    "                           \"INCKEY\",\\\n",
    "                           \"COLDETKEY\",\\\n",
    "                           \"REPORTNO\",\\\n",
    "                           \"INTKEY\",\\\n",
    "                           \"LOCATION\",\\\n",
    "                           \"EXCEPTRSNCODE\",\\\n",
    "                           \"EXCEPTRSNDESC\",\\\n",
    "                           \"SEVERITYDESC\",\\\n",
    "                           \"INCDATE\",\\\n",
    "                           \"INCDTTM\",\\\n",
    "                           \"JUNCTIONTYPE\",\\\n",
    "                           \"SDOT_COLCODE\",\\\n",
    "                           \"SDOT_COLDESC\",\\\n",
    "                           \"INATTENTIONIND\",\\\n",
    "                           \"UNDERINFL\",\\\n",
    "                           \"PEDROWNOTGRNT\",\\\n",
    "                           \"SDOTCOLNUM\",\\\n",
    "                           \"SPEEDING\",\\\n",
    "                           \"ST_COLCODE\",\\\n",
    "                           \"ST_COLDESC\",\\\n",
    "                           \"SEGLANEKEY\",\\\n",
    "                           \"CROSSWALKKEY\",\\\n",
    "                           \"HITPARKEDCAR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the selected columns from the DataFrame after converting unknowns to NaN.\n",
    "# Store the result in a new DataFrame.\n",
    "df_drop_columns = df_unknowns_converted_to_nan.drop(columns=list_of_columns_to_drop, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any row that contains at least one NaN.\n",
    "df_drop_columns_and_rows = df_drop_columns.dropna(axis=\"index\", how=\"any\", thresh=None, subset=None, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 18.245205821003765 seconds.\n"
     ]
    }
   ],
   "source": [
    "print_elapsed_time(notebook_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"correct_data_format\">Correct Data Format</h3>\n",
    "\n",
    "Ensure that each data type is appropriate for the corresponding feature.\n",
    "Cast columns of type \"object\" as type \"category\", but leave all other column types unaltered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame to store converted data types.\n",
    "df_converted = pd.DataFrame()\n",
    "\n",
    "for column in list(df_drop_columns_and_rows.columns):\n",
    "    if (df_drop_columns_and_rows[column].dtype in [np.dtype('object')]):\n",
    "        df_converted[column] = df_drop_columns_and_rows[column].astype('category')\n",
    "    # Copy all other columns to new DataFrame without changing their types.\n",
    "    else:\n",
    "        df_converted[column] = df_drop_columns_and_rows[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of categorical columns.\n",
    "df_categorical = df_converted.select_dtypes(include=\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 18.914936563989613 seconds.\n"
     ]
    }
   ],
   "source": [
    "print_elapsed_time(notebook_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"feature_selection\">Feature selection</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features before One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEVERITYCODE</th>\n",
       "      <th>COLLISIONTYPE</th>\n",
       "      <th>WEATHER</th>\n",
       "      <th>ROADCOND</th>\n",
       "      <th>LIGHTCOND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sideswipe</td>\n",
       "      <td>Raining</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Dark - Street Lights On</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Parked Car</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Daylight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Rear Ended</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Daylight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Wet</td>\n",
       "      <td>Daylight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Sideswipe</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Daylight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  SEVERITYCODE COLLISIONTYPE   WEATHER ROADCOND                LIGHTCOND\n",
       "0            1     Sideswipe   Raining      Wet  Dark - Street Lights On\n",
       "1            1    Parked Car     Clear      Dry                 Daylight\n",
       "5            1    Rear Ended     Clear      Dry                 Daylight\n",
       "6            1         Other     Clear      Wet                 Daylight\n",
       "8            1     Sideswipe  Overcast      Dry                 Daylight\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 171872 entries, 0 to 221388\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count   Dtype   \n",
      "---  ------         --------------   -----   \n",
      " 0   SEVERITYCODE   171872 non-null  category\n",
      " 1   COLLISIONTYPE  171872 non-null  category\n",
      " 2   WEATHER        171872 non-null  category\n",
      " 3   ROADCOND       171872 non-null  category\n",
      " 4   LIGHTCOND      171872 non-null  category\n",
      "dtypes: category(5)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_categorical.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 19.290964265994262 seconds.\n"
     ]
    }
   ],
   "source": [
    "print_elapsed_time(notebook_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"imbalanced_data\">Dealing with Imbalanced Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data is imbalanced, we split the DataFrame into four DataFrames, one for each value of the SEVERITYCODE feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEVERITYCODE relative frequencies:\n",
      "1    0.657943120\n",
      "2    0.323036911\n",
      "2b   0.017111571\n",
      "3    0.001908397\n",
      "Name: SEVERITYCODE, Length: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"SEVERITYCODE relative frequencies:\")\n",
    "print(df_categorical[\"SEVERITYCODE\"].value_counts(normalize=True, dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEVERITYCODE relative frequencies:\n",
      "1     113082\n",
      "2      55521\n",
      "2b      2941\n",
      "3        328\n",
      "Name: SEVERITYCODE, Length: 4, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"SEVERITYCODE relative frequencies:\")\n",
    "print(df_categorical[\"SEVERITYCODE\"].value_counts(normalize=False, dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1 = df_categorical[df_categorical['SEVERITYCODE'] == '1']\n",
    "df_class_2 = df_categorical[df_categorical['SEVERITYCODE'] == '2']\n",
    "df_class_2b = df_categorical[df_categorical['SEVERITYCODE'] == '2b']\n",
    "df_class_3 = df_categorical[df_categorical['SEVERITYCODE'] == '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEVERITYCODE relative frequencies:\n",
      "1     113082\n",
      "3          0\n",
      "2b         0\n",
      "2          0\n",
      "Name: SEVERITYCODE, Length: 4, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"SEVERITYCODE relative frequencies:\")\n",
    "print(df_class_1[\"SEVERITYCODE\"].value_counts(normalize=False, dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEVERITYCODE relative frequencies:\n",
      "2     55521\n",
      "3         0\n",
      "2b        0\n",
      "1         0\n",
      "Name: SEVERITYCODE, Length: 4, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"SEVERITYCODE relative frequencies:\")\n",
    "print(df_class_2[\"SEVERITYCODE\"].value_counts(normalize=False, dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEVERITYCODE relative frequencies:\n",
      "2b    2941\n",
      "3        0\n",
      "2        0\n",
      "1        0\n",
      "Name: SEVERITYCODE, Length: 4, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"SEVERITYCODE relative frequencies:\")\n",
    "print(df_class_2b[\"SEVERITYCODE\"].value_counts(normalize=False, dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEVERITYCODE relative frequencies:\n",
      "3     328\n",
      "2b      0\n",
      "2       0\n",
      "1       0\n",
      "Name: SEVERITYCODE, Length: 4, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"SEVERITYCODE relative frequencies:\")\n",
    "print(df_class_3[\"SEVERITYCODE\"].value_counts(normalize=False, dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 1 size = 113082\n",
      "class 2 size = 55521\n",
      "class 2b size = 2941\n",
      "class 3 size = 328\n",
      "\n",
      "minority class size = 328\n"
     ]
    }
   ],
   "source": [
    "# Store and print the size of the all classes.\n",
    "class_1_size = len(df_class_1)\n",
    "class_2_size = len(df_class_2)\n",
    "class_2b_size = len(df_class_2b)\n",
    "class_3_size = len(df_class_3)\n",
    "print('class 1 size =', class_1_size)\n",
    "print('class 2 size =', class_2_size)\n",
    "print('class 2b size =', class_2b_size)\n",
    "print('class 3 size =', class_3_size)\n",
    "print()\n",
    "# Store and print the size of the minority class.\n",
    "minority_class_size = len(df_class_3)\n",
    "print('minority class size =', minority_class_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 20.407963084988296 seconds.\n"
     ]
    }
   ],
   "source": [
    "print_elapsed_time(notebook_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id='oversampling_with_replacement'>Oversampling the non-majority classes with Replacement: samples per class = Size of Class '2'</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size_class_1 = np.int(class_2_size)\n",
    "sample_size_class_2 = np.int(class_2_size)\n",
    "sample_size_class_2b = np.int(class_2_size)\n",
    "sample_size_class_3 = np.int(class_2_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-d68eb3b4259f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_class_1_sampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_class_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_size_class_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_class_2_sampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_class_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_size_class_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_class_2b_sampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_class_2b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_size_class_2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_class_3_sampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_class_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_size_class_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   5059\u001b[0m             )\n\u001b[1;32m   5060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5061\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5062\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "# For each non-minority class, undersample this class by resampling it for a number of samples equal to the size of the minority class.\n",
    "df_class_1_sampled = df_class_1.sample(n=sample_size_class_1, replace=False, weights=None, axis='index', random_state=seed)\n",
    "df_class_2_sampled = df_class_2.sample(n=sample_size_class_2, replace=False, weights=None, axis='index', random_state=seed)\n",
    "df_class_2b_sampled = df_class_2b.sample(n=sample_size_class_2b, replace=True, weights=None, axis='index', random_state=seed)\n",
    "df_class_3_sampled = df_class_3.sample(n=sample_size_class_3, replace=True, weights=None, axis='index', random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a new DataFrame by concatenating the minority class's DataFrame with the undersampled resamples of the non-minority classes.\n",
    "df_balanced_not_shuffled = pd.concat([df_class_1_sampled, df_class_2_sampled, df_class_2b_sampled, df_class_3_sampled], axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the new balanced DataFrame and store it for subsequent train/test splits.\n",
    "df_balanced_oversampled = shuffle(df_balanced_not_shuffled, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the new DataFrame is balanced.\n",
    "print(\"SEVERITYCODE relative frequencies:\")\n",
    "print(df_balanced_oversampled[\"SEVERITYCODE\"].value_counts(normalize=False, dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the new DataFrame is balanced.\n",
    "print(\"SEVERITYCODE relative frequencies:\")\n",
    "print(df_balanced_oversampled[\"SEVERITYCODE\"].value_counts(normalize=True, dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a feature set represented by the DataFrame X. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_balanced_oversampled[[\"COLLISIONTYPE\", \"WEATHER\", \"ROADCOND\", \"LIGHTCOND\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define the data for the target variable, SEVERITYCODE, by the array y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_balanced_oversampled[\"SEVERITYCODE\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time(notebook_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize the data by transforming it so that it is compatible\n",
    "with the machine learning estimators we use in this notebook.\n",
    "We use special care with sparse matrix data so as to not destroy the\n",
    "structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder and fit it to the features.\n",
    "# Transform the data into a sparse matrix by passing the parameter sparse=True by default.\n",
    "start_time = default_timer()\n",
    "print(\"Fitting OneHotEncoder to training data...\")\n",
    "encoder = OneHotEncoder(sparse=True)\n",
    "X = encoder.fit_transform(X)\n",
    "print(\"Completed in\", elapsed_time(start_time), \"seconds.\")\n",
    "# Display the categories of the encoder.\n",
    "print(encoder.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time(notebook_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"logistic_regression_oversampling\">Building a Logistic Regression Model through Oversampling<\\h2>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### NOTE:\n",
    "LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "sorted(sklearn.metrics.SCORERS.keys()) : to get valid options for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = default_timer()\n",
    "kfold_cv = KFold(n_splits=10)\n",
    "logistic_regression_clf = make_pipeline(\\\n",
    "    StandardScaler(with_mean=False),\\\n",
    "    LogisticRegression(solver='saga', multi_class='auto', penalty='l1', max_iter=100, n_jobs=-1, random_state=seed), verbose=True)\n",
    "scoring = ['f1_macro', 'neg_log_loss','precision_macro', 'recall_macro']\n",
    "logistic_regression_oversampling_scores = cross_validate(logistic_regression_clf, X, y, scoring=scoring, n_jobs=-1, cv=kfold_cv, return_estimator=True)\n",
    "print(\"Logistic regression through oversampling score keys:\", sorted(logistic_regression_oversampling_scores.keys()))\n",
    "print_elapsed_time(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sorted(logistic_regression_oversampling_scores.keys()):\n",
    "    if key != 'estimator':\n",
    "        print('%s: mean = %f, std = %f' % (key, np.mean(logistic_regression_oversampling_scores[key]), np.std(logistic_regression_oversampling_scores[key])), sep='')\n",
    "        print('%s :%s' % (key, logistic_regression_oversampling_scores[key]), sep='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time(notebook_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"svm_oversampling\">Building a Support Vector Machine through Oversampling without Replacement<\\h2>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### NOTE:\n",
    "LinearSVC(penalty='l2', loss='squared_hinge', *, dual=True, tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = default_timer()\n",
    "kfold_cv = KFold(n_splits=10)\n",
    "linear_svc_clf = LinearSVC(penalty='l1', dual=False, random_state=seed, max_iter=1000)\n",
    "scoring = ['f1_macro', 'precision_macro', 'recall_macro']\n",
    "linear_svc_oversampling_scores = cross_validate(linear_svc_clf, X, y, scoring=scoring, n_jobs=-1, cv=kfold_cv, return_estimator=True)\n",
    "print(\"Linear SVM through undersampling score keys:\", sorted(linear_svc_oversampling_scores.keys()))\n",
    "print_elapsed_time(t0)\n",
    "\n",
    "t0 = default_timer()\n",
    "kfold_cv = KFold(n_splits=10)\n",
    "linear_svc_clf = make_pipeline(\\\n",
    "    StandardScaler(with_mean=False),\\\n",
    "    LinearSVC(penalty='l1', dual=False, random_state=seed, max_iter=1000), verbose=True)\n",
    "scoring = ['f1_macro', 'precision_macro', 'recall_macro']\n",
    "linear_svc_oversampling_scores = cross_validate(linear_svc_clf, X, y, scoring=scoring, n_jobs=-1, cv=kfold_cv, return_estimator=True)\n",
    "print(\"Linear SVM through oversampling score keys:\", sorted(logistic_regression_oversampling_scores.keys()))\n",
    "print_elapsed_time(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sorted(linear_svc_oversampling_scores.keys()):\n",
    "    if key != 'estimator':\n",
    "        print('%s: mean = %f, std = %f' % (key, np.mean(linear_svc_oversampling_scores[key]), np.std(linear_svc_oversampling_scores[key])), sep='')\n",
    "        print('%s :%s' % (key, linear_svc_oversampling_scores[key]), sep='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time(notebook_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check: Manually Split the Oversampled Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=np.int(os.times()[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(logistic_regression_oversampling_scores['estimator']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_confusion_matrix(estimator, X, y_true, *, labels=None, sample_weight=None, normalize=None, display_labels=None, include_values=True, xticks_rotation='horizontal', values_format=None, cmap='viridis', ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each logistic regression classifier in the cross-validation, print the Jaccard score for each class.\n",
    "for index, lr_clf in zip(range(len(logistic_regression_oversampling_scores['estimator'])), logistic_regression_oversampling_scores['estimator']):\n",
    "    lr_clf_score = lr_clf.score(X_test, y_test)\n",
    "    y_test_predicted = lr_clf.predict(X_test)\n",
    "    lr_clf_jaccard_scores = jaccard_score(y_test, y_test_predicted, average=None, labels=['1', '2', '2b', '3'])\n",
    "    print('Model %d:' % (index))\n",
    "    print('lr_clf mean accuracy =', lr_clf_score)\n",
    "    print('Jaccard scores by class ', lr_clf_jaccard_scores)\n",
    "    print(classification_report(y_test, y_test_predicted, labels=['1', '2', '2b', '3'], target_names=['1', '2', '2b', '3'], digits=6))\n",
    "    \n",
    "    # Create a figure.\n",
    "    fig = plt.figure(num=str(index), figsize=(6.4 * 2, 4.8))\n",
    "    fig.suptitle('Confusion Matrices for Model %d:' % (index), fontsize=20)\n",
    "    \n",
    "    ax = plt.subplot(1,2,1)\n",
    "    ax.set_title(\"Normalized Over Predicted Conditions\", fontsize=14)\n",
    "    plot_confusion_matrix(lr_clf, X_test, y_test, labels=['1', '2', '2b', '3'], display_labels=['1', '2', '2b', '3'], normalize='pred', ax=ax)\n",
    "    \n",
    "    ax = plt.subplot(1,2,2)\n",
    "    ax.set_title(\"Normalized Over True Conditions\", fontsize=14)\n",
    "    plot_confusion_matrix(lr_clf, X_test, y_test, labels=['1', '2', '2b', '3'], display_labels=['1', '2', '2b', '3'], normalize='true', ax=ax)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(linear_svc_oversampling_scores['estimator']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each support vector machine classifier in the cross-validation, print the Jaccard score for each class.\n",
    "for index, linear_svc_clf in zip(range(len(linear_svc_oversampling_scores['estimator'])), linear_svc_oversampling_scores['estimator']):\n",
    "    linear_svc_score = linear_svc_clf.score(X_test, y_test)\n",
    "    y_test_predicted = linear_svc_clf.predict(X_test)\n",
    "    linear_svc_jaccard_scores = jaccard_score(y_test, y_test_predicted, average=None, labels=['1', '2', '2b', '3'])\n",
    "    print('Model %d:' % (index))\n",
    "    print('linear_svc_clf mean accuracy =', linear_svc_score)\n",
    "    print('Jaccard scores by class ', linear_svc_jaccard_scores)\n",
    "    print(classification_report(y_test, y_test_predicted, labels=['1', '2', '2b', '3'], target_names=['1', '2', '2b', '3'], digits=6))\n",
    "\n",
    "    # Create a figure.\n",
    "    fig = plt.figure(num=str(index), figsize=(6.4 * 2, 4.8))\n",
    "    fig.suptitle('Confusion Matrices for Model %d:' % (index), fontsize=20)\n",
    "    \n",
    "    ax = plt.subplot(1,2,1)\n",
    "    ax.set_title(\"Normalized over predicted conditions\", fontsize=14)\n",
    "    plot_confusion_matrix(linear_svc_clf, X_test, y_test, labels=['1', '2', '2b', '3'], display_labels=['1', '2', '2b', '3'], normalize='pred', ax=ax)\n",
    "    \n",
    "    ax = plt.subplot(1,2,2)\n",
    "    ax.set_title(\"Normalized over true conditions\", fontsize=14)\n",
    "    plot_confusion_matrix(linear_svc_clf, X_test, y_test, labels=['1', '2', '2b', '3'], display_labels=['1', '2', '2b', '3'], normalize='true', ax=ax)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Graphics and reports generated in %f seconds' % elapsed_time(t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_elapsed_time(notebook_start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
