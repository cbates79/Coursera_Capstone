{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the Severity of Automobile Accidents in Seattle, Washington ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first week, you will discover your\n",
    "project objectives, find your dataset that you will use for this capstone project, and publish your\n",
    "dataset on GitHub.\n",
    "\n",
    "In the second week, you will build your machine\n",
    "learning solution.\n",
    "\n",
    "In the third week,\n",
    "you will finalize your model and be ready\n",
    "to submit your work.\n",
    "\n",
    "To complete capstone,\n",
    "you will be working on a case study which is to predict the severity\n",
    "of an accident.\n",
    "Now, wouldn't it be great if there were something in place that could warn you, \n",
    "given the weather and the road conditions,\n",
    "about the possibility of you getting into a car accident and how severe it would be,\n",
    "so that you would drive more carefully or even change your travel plans?\n",
    "Let's use our shared data for Seattle, Washington as an example of how to deal with the accidents data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting display options...\n",
      "max_info_columns: 500\n",
      "max_info_rows: 1000\n",
      "max_columns: 500\n",
      "max_rows: 1000\n",
      "precision: 9\n",
      "max_seq_items: None\n",
      "show_dimensions: True\n",
      "max_categories: 1000000\n",
      "max_colwidth: 500\n",
      "float_format: <function <lambda> at 0x7f541dfe9820>\n"
     ]
    }
   ],
   "source": [
    "# NOTE: >>> help(pd.options.display. <TAB>\n",
    "# pd.options.display.chop_threshold      pd.options.display.float_format        pd.options.display.max_info_columns    pd.options.display.notebook_repr_html\n",
    "# pd.options.display.colheader_justify   pd.options.display.html                pd.options.display.max_info_rows       pd.options.display.pprint_nest_depth\n",
    "# pd.options.display.column_space        pd.options.display.large_repr          pd.options.display.max_rows            pd.options.display.precision\n",
    "# pd.options.display.date_dayfirst       pd.options.display.latex               pd.options.display.max_seq_items       pd.options.display.show_dimensions\n",
    "# pd.options.display.date_yearfirst      pd.options.display.max_categories      pd.options.display.memory_usage        pd.options.display.unicode\n",
    "# pd.options.display.encoding            pd.options.display.max_columns         pd.options.display.min_rows            pd.options.display.width\n",
    "# pd.options.display.expand_frame_repr   pd.options.display.max_colwidth        pd.options.display.multi_sparse        \n",
    "\n",
    "# Create a list of display options.\n",
    "list_of_display_options_fully_qualified_names = str(\\\n",
    "\"pd.options.display.chop_threshold, pd.options.display.float_format, pd.options.display.max_info_columns, pd.options.display.notebook_repr_html, \\\n",
    "pd.options.display.colheader_justify, pd.options.display.html, pd.options.display.max_info_rows, pd.options.display.pprint_nest_depth, \\\n",
    "pd.options.display.column_space, pd.options.display.large_repr, pd.options.display.max_rows, pd.options.display.precision, \\\n",
    "pd.options.display.date_dayfirst, pd.options.display.latex, pd.options.display.max_seq_items, pd.options.display.show_dimensions, \\\n",
    "pd.options.display.date_yearfirst, pd.options.display.max_categories, pd.options.display.memory_usage, pd.options.display.unicode, \\\n",
    "pd.options.display.encoding, pd.options.display.max_columns, pd.options.display.min_rows, pd.options.display.width, \\\n",
    "pd.options.display.expand_frame_repr, pd.options.display.max_colwidth, pd.options.display.multi_sparse\").split(sep=', ')\n",
    "\n",
    "# Initialize an empty list to store all the short names for display options.\n",
    "list_of_display_options_short_names = list()\n",
    "# For each fully qualified option name,\n",
    "# get the option's short name and add it to the list of short names.\n",
    "for fully_qualified_option_name in list_of_display_options_fully_qualified_names:\n",
    "    # Get short option name.\n",
    "    short_option_name = fully_qualified_option_name.split(sep='.')[-1]\n",
    "    \n",
    "    # Add short option name to list of display option short names.\n",
    "    list_of_display_options_short_names.append(short_option_name)\n",
    "\n",
    "# Define dictionary of display option settings.\n",
    "dict_of_display_option_settings_short_names=\\\n",
    "{\"max_info_columns\": 500,\\\n",
    "\"max_info_rows\": 1000,\\\n",
    "\"max_columns\": 500,\\\n",
    "\"max_rows\": 1000,\\\n",
    "\"precision\": 9,\\\n",
    "\"max_seq_items\": None,\\\n",
    "\"show_dimensions\": True,\\\n",
    "\"max_categories\": 1000000,\\\n",
    "\"max_colwidth\": 500,\\\n",
    "\"float_format\": lambda x: '%.9f' % x}\n",
    "\n",
    "# Set pandas display options using dictionary of short names,\n",
    "# and display the options/value pairs.\n",
    "print(\"Setting display options...\")\n",
    "for key in list(dict_of_display_option_settings_short_names.keys()):\n",
    "    # Set display option.\n",
    "    pd.set_option(key, dict_of_display_option_settings_short_names[key])\n",
    "    # Print display option name and value.\n",
    "    print(key, \": \", pd.get_option(key), sep='')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(os.listdir(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute Information URL: https://www.seattle.gov/Documents/Departments/SDOT/GIS/Collisions_OD.pdf\n",
    "# Read the Collisions Data CSV file and store it as a DataFrame.\n",
    "# url=\"https://opendata.arcgis.com/datasets/5b5c745e0f1f48e7a53acec63a0022ab_0.csv\" # HTTPError at 202009151050, using local copy of .csv instead.\n",
    "local_path_to_csv = \"../Collisions.csv\"\n",
    "df=pd.read_csv(local_path_to_csv, low_memory=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# View the first few rows of the collisions DataFrame.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"data_wrangling\">Data Wrangling</h2>\n",
    "\n",
    "Steps for working with missing data:\n",
    "<ol>\n",
    "    <li>Identify missing data.</li>\n",
    "    <li>Deal with missing data.</li>\n",
    "    <li>Correct data format.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"identifying_missing_data\">Identifying Missing Data</h3>\n",
    "\n",
    "The missing values are converted to Python's default. We use Python's built-in functions to identify these missing values. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test whether the collisions DataFrame has NaN values.\n",
    "if df.isna().any(axis=None):\n",
    "    print(\"DataFrame has NaN.\")\n",
    "else:\n",
    "    print(\"DataFrame has no NaN.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Initialize a list to store the labels for the columns with missing data.\n",
    "list_of_columns_with_missing_data = list()\n",
    "\n",
    "# For each column in the collisions DataFrame,\n",
    "# if the column contains at least one NaN, \n",
    "# then add the column's label to the list.\n",
    "for column in list(df.columns):\n",
    "    if df[column].hasnans:\n",
    "        list_of_columns_with_missing_data.append(column)\n",
    "\n",
    "# Print the number of columns\n",
    "print(\"Number of columns: %d\" % len(df.columns))\n",
    "print(\"List of columns labels:\")\n",
    "print(list(df.columns))\n",
    "print()\n",
    "print(\"Number of columns missing data: %d\" % len(list_of_columns_with_missing_data))\n",
    "print(\"List of columns missing data:\")\n",
    "print(list_of_columns_with_missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"deal_with_missing_data\">Deal with Missing Data</h3>\n",
    "\n",
    "<ol>\n",
    "    <li>Drop the Data\n",
    "        <ol>\n",
    "            <li>Drop entire row.</li>\n",
    "            <li>Drop entire column.</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>Replace the Data\n",
    "        <ol>\n",
    "            <li>Replace data by mean.</li>\n",
    "            <li>Replace data by frequency.</li>\n",
    "            <li>Replace data based on other functions.</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "        \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whole columns should be dropped only if most entries in the column are empty."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### DELETE THIS CELL BEFORE PRODUCTION ###\n",
    "\n",
    "# Print a list of all the column labels for the collisions DataFrame.\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### DELETE THIS CELL BEFORE PRODUCTION ###\n",
    "\n",
    "# NOTE: astype(self: ~FrameOrSeries, dtype, copy: bool = True, errors: str = 'raise') -> ~FrameOrSeries \n",
    "#    dtype : data type, or dict of column name -> data type\n",
    "#        Use a numpy.dtype or Python type to cast entire pandas object to\n",
    "#        the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
    "#        column label and dtype is a numpy.dtype or Python type to cast one\n",
    "#        or more of the DataFrame's columns to column-specific types.\n",
    "\n",
    "# For each column in collision DataFrame:\n",
    "# (1) print statistical description and relative frequencies of the data;\n",
    "# (2) cast column to categorical type and print a statistical description and \n",
    "#     the relative frequencies of the categorical data in the column.\n",
    "for column in list(df.columns):\n",
    "    print(column, \": original data type: \", df[column].dtype, sep='')\n",
    "    print(\"Statistics as type category:\")\n",
    "    print(df[[column]].astype(dtype=\"category\").describe(include=\"all\"))\n",
    "    print(\"Relative frequencies as type category:\")\n",
    "    print(df[column].astype(dtype=\"category\").value_counts(normalize=True, dropna=False))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any column from the collisions DataFrame if it satisfies at least one of the following conditions:\n",
    "# 1) more than 15% of the column's data is NaN;\n",
    "# 2) the column only contains unique identification keys;\n",
    "# 3) it is unclear how the column's data should be interpreted.\n",
    "\n",
    "list_of_columns_to_drop = [\\\n",
    "                           \"OBJECTID\",\\\n",
    "                           \"INCKEY\",\\\n",
    "                           \"COLDETKEY\",\\\n",
    "                           \"REPORTNO\",\\\n",
    "                           \"INTKEY\",\\\n",
    "                           \"EXCEPTRSNCODE\",\\\n",
    "                           \"EXCEPTRSNDESC\",\\\n",
    "                           \"INATTENTIONIND\",\\\n",
    "                           \"PEDROWNOTGRNT\",\\\n",
    "                           \"SDOTCOLNUM\",\\\n",
    "                           \"SPEEDING\",\\\n",
    "                           \"SEGLANEKEY\",\\\n",
    "                           \"CROSSWALKKEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
    "# Drop the selected columns from the collisions DataFrame\n",
    "# and store the result in a new DataFrame.\n",
    "df_after_drop_columns = df.drop(columns=list_of_columns_to_drop, inplace=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print the first few rows of the DataFrame after dropping columns.\n",
    "df_after_drop_columns.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test whether DataFrame has NaN after dropping columns.\n",
    "if df_after_drop_columns.isna().any(axis=None):\n",
    "    print(\"DataFrame has NaN.\")\n",
    "else:\n",
    "    print(\"DataFrame has no NaN.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print a concise, technical summary of the collisions DataFrame.\n",
    "df_after_drop_columns.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# For each column in DataFrame after dropping columns,\n",
    "# print the relative frequencies of values and a description\n",
    "# of the columns data.\n",
    "for column in df_after_drop_columns.columns:\n",
    "    print(\"Relative frequency:\")\n",
    "    print(df_after_drop_columns[column].value_counts(normalize=True, dropna=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "\n",
    "# Drop any row that contains at least one NaN.\n",
    "#print(\"Number of columns: %d\" % len(list(df_after_drop_columns.columns)))\n",
    "df_after_drop_columns_and_rows = df_after_drop_columns.dropna(axis=\"index\", how=\"any\", thresh=None, subset=None, inplace=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Verify that DataFrame has no NaN after dropping columns and rows.\n",
    "if df_after_drop_columns_and_rows.isna().any(axis=None):\n",
    "    print(\"DataFrame has NaN.\")\n",
    "else:\n",
    "    print(\"DataFrame has no NaN.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# NOTE: info(self, verbose=None, buf=None, max_cols=None, memory_usage=None, null_counts=None) -> None\n",
    "df_after_drop_columns_and_rows.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"correct_data_format\">Correct Data Format</h3>\n",
    "\n",
    "Ensure that each data type is appropriate for the corresponding feature.\n",
    "Convert integer data to categorical type if the \"real-world\" measurement is not\n",
    "\"naturally ordered\" as on the number line.\n",
    "If data represents date, time, or date/time information, then convert the data to the appropriate datetime representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame to store converted data types.\n",
    "df_converted = pd.DataFrame()\n",
    "\n",
    "for column in list(df_after_drop_columns_and_rows.columns):\n",
    "     # Cast column \"ST_COLCODE\" to type category.\n",
    "    if column in [\"SDOT_COLCODE\"]:\n",
    "        df_converted[\"SDOT_COLCODE\"] = df_after_drop_columns_and_rows[\"SDOT_COLCODE\"].astype('category')\n",
    "    # Cast columns \"INCDATE\" and \"INCDTTM\" to type datetime.\n",
    "    elif column in [\"INCDATE\", \"INCDTTM\"]:\n",
    "        df_converted[column] = pd.to_datetime(df_after_drop_columns_and_rows[column], infer_datetime_format=True)\n",
    "    # Cast columns of type object to type category.\n",
    "    elif (df_after_drop_columns_and_rows[column].dtype in [np.dtype('object')]):\n",
    "        df_converted[column] = df_after_drop_columns_and_rows[column].astype('category')\n",
    "    # Copy all other columns to new DataFrame without changing their types.\n",
    "    else:\n",
    "        df_converted[column] = df_after_drop_columns_and_rows[column]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_converted.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Verify that DataFrame has no NaN .\n",
    "if df_converted.isna().any(axis=None):\n",
    "    print(\"DataFrame has NaN.\")\n",
    "else:\n",
    "    print(\"DataFrame has no NaN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 185317 entries, 0 to 221388\n",
      "Data columns (total 27 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   X                185317 non-null  float64       \n",
      " 1   Y                185317 non-null  float64       \n",
      " 2   STATUS           185317 non-null  category      \n",
      " 3   ADDRTYPE         185317 non-null  category      \n",
      " 4   LOCATION         185317 non-null  category      \n",
      " 5   SEVERITYCODE     185317 non-null  category      \n",
      " 6   SEVERITYDESC     185317 non-null  category      \n",
      " 7   COLLISIONTYPE    185317 non-null  category      \n",
      " 8   PERSONCOUNT      185317 non-null  int64         \n",
      " 9   PEDCOUNT         185317 non-null  int64         \n",
      " 10  PEDCYLCOUNT      185317 non-null  int64         \n",
      " 11  VEHCOUNT         185317 non-null  int64         \n",
      " 12  INJURIES         185317 non-null  int64         \n",
      " 13  SERIOUSINJURIES  185317 non-null  int64         \n",
      " 14  FATALITIES       185317 non-null  int64         \n",
      " 15  INCDATE          185317 non-null  datetime64[ns]\n",
      " 16  INCDTTM          185317 non-null  datetime64[ns]\n",
      " 17  JUNCTIONTYPE     185317 non-null  category      \n",
      " 18  SDOT_COLCODE     185317 non-null  category      \n",
      " 19  SDOT_COLDESC     185317 non-null  category      \n",
      " 20  UNDERINFL        185317 non-null  category      \n",
      " 21  WEATHER          185317 non-null  category      \n",
      " 22  ROADCOND         185317 non-null  category      \n",
      " 23  LIGHTCOND        185317 non-null  category      \n",
      " 24  ST_COLCODE       185317 non-null  category      \n",
      " 25  ST_COLDESC       185317 non-null  category      \n",
      " 26  HITPARKEDCAR     185317 non-null  category      \n",
      "dtypes: category(16), datetime64[ns](2), float64(2), int64(7)\n",
      "memory usage: 20.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Display info about new DataFrame after casting objects to category or date\n",
    "df_converted.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCDATE</th>\n",
       "      <th>INCDTTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>2020-01-22 15:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>2020-01-07 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>2020-06-11 17:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>2020-02-03 09:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>2020-01-30 08:32:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     INCDATE             INCDTTM\n",
       "0 2020-01-22 2020-01-22 15:21:00\n",
       "1 2020-01-07 2020-01-07 08:00:00\n",
       "5 2020-06-11 2020-06-11 17:07:00\n",
       "6 2020-02-03 2020-02-03 09:49:00\n",
       "8 2020-01-30 2020-01-30 08:32:00\n",
       "\n",
       "[5 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first several rows of columns INCDATE and INCDTTM.\n",
    "df_converted[[\"INCDATE\", \"INCDTTM\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>PERSONCOUNT</th>\n",
       "      <th>PEDCOUNT</th>\n",
       "      <th>PEDCYLCOUNT</th>\n",
       "      <th>VEHCOUNT</th>\n",
       "      <th>INJURIES</th>\n",
       "      <th>SERIOUSINJURIES</th>\n",
       "      <th>FATALITIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>1.000000000</td>\n",
       "      <td>-0.160521960</td>\n",
       "      <td>0.012071865</td>\n",
       "      <td>0.010809063</td>\n",
       "      <td>-0.003834269</td>\n",
       "      <td>-0.015810624</td>\n",
       "      <td>0.011208065</td>\n",
       "      <td>-0.006274326</td>\n",
       "      <td>-0.000091933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>-0.160521960</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>-0.013397357</td>\n",
       "      <td>0.012962509</td>\n",
       "      <td>0.027700106</td>\n",
       "      <td>0.018114148</td>\n",
       "      <td>0.010610046</td>\n",
       "      <td>-0.000691186</td>\n",
       "      <td>-0.004291236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERSONCOUNT</th>\n",
       "      <td>0.012071865</td>\n",
       "      <td>-0.013397357</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>-0.023841139</td>\n",
       "      <td>-0.043475206</td>\n",
       "      <td>0.395787500</td>\n",
       "      <td>0.273671170</td>\n",
       "      <td>0.105816709</td>\n",
       "      <td>0.047709077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEDCOUNT</th>\n",
       "      <td>0.010809063</td>\n",
       "      <td>0.012962509</td>\n",
       "      <td>-0.023841139</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>-0.021584911</td>\n",
       "      <td>-0.329870583</td>\n",
       "      <td>0.157640710</td>\n",
       "      <td>0.129484025</td>\n",
       "      <td>0.073938403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEDCYLCOUNT</th>\n",
       "      <td>-0.003834269</td>\n",
       "      <td>0.027700106</td>\n",
       "      <td>-0.043475206</td>\n",
       "      <td>-0.021584911</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>-0.313565246</td>\n",
       "      <td>0.113270524</td>\n",
       "      <td>0.059977965</td>\n",
       "      <td>0.010630242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEHCOUNT</th>\n",
       "      <td>-0.015810624</td>\n",
       "      <td>0.018114148</td>\n",
       "      <td>0.395787500</td>\n",
       "      <td>-0.329870583</td>\n",
       "      <td>-0.313565246</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.023013754</td>\n",
       "      <td>-0.046766713</td>\n",
       "      <td>-0.028869204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INJURIES</th>\n",
       "      <td>0.011208065</td>\n",
       "      <td>0.010610046</td>\n",
       "      <td>0.273671170</td>\n",
       "      <td>0.157640710</td>\n",
       "      <td>0.113270524</td>\n",
       "      <td>0.023013754</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.280833962</td>\n",
       "      <td>0.068237339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SERIOUSINJURIES</th>\n",
       "      <td>-0.006274326</td>\n",
       "      <td>-0.000691186</td>\n",
       "      <td>0.105816709</td>\n",
       "      <td>0.129484025</td>\n",
       "      <td>0.059977965</td>\n",
       "      <td>-0.046766713</td>\n",
       "      <td>0.280833962</td>\n",
       "      <td>1.000000000</td>\n",
       "      <td>0.177365053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FATALITIES</th>\n",
       "      <td>-0.000091933</td>\n",
       "      <td>-0.004291236</td>\n",
       "      <td>0.047709077</td>\n",
       "      <td>0.073938403</td>\n",
       "      <td>0.010630242</td>\n",
       "      <td>-0.028869204</td>\n",
       "      <td>0.068237339</td>\n",
       "      <td>0.177365053</td>\n",
       "      <td>1.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           X            Y  PERSONCOUNT     PEDCOUNT  \\\n",
       "X                1.000000000 -0.160521960  0.012071865  0.010809063   \n",
       "Y               -0.160521960  1.000000000 -0.013397357  0.012962509   \n",
       "PERSONCOUNT      0.012071865 -0.013397357  1.000000000 -0.023841139   \n",
       "PEDCOUNT         0.010809063  0.012962509 -0.023841139  1.000000000   \n",
       "PEDCYLCOUNT     -0.003834269  0.027700106 -0.043475206 -0.021584911   \n",
       "VEHCOUNT        -0.015810624  0.018114148  0.395787500 -0.329870583   \n",
       "INJURIES         0.011208065  0.010610046  0.273671170  0.157640710   \n",
       "SERIOUSINJURIES -0.006274326 -0.000691186  0.105816709  0.129484025   \n",
       "FATALITIES      -0.000091933 -0.004291236  0.047709077  0.073938403   \n",
       "\n",
       "                 PEDCYLCOUNT     VEHCOUNT    INJURIES  SERIOUSINJURIES  \\\n",
       "X               -0.003834269 -0.015810624 0.011208065     -0.006274326   \n",
       "Y                0.027700106  0.018114148 0.010610046     -0.000691186   \n",
       "PERSONCOUNT     -0.043475206  0.395787500 0.273671170      0.105816709   \n",
       "PEDCOUNT        -0.021584911 -0.329870583 0.157640710      0.129484025   \n",
       "PEDCYLCOUNT      1.000000000 -0.313565246 0.113270524      0.059977965   \n",
       "VEHCOUNT        -0.313565246  1.000000000 0.023013754     -0.046766713   \n",
       "INJURIES         0.113270524  0.023013754 1.000000000      0.280833962   \n",
       "SERIOUSINJURIES  0.059977965 -0.046766713 0.280833962      1.000000000   \n",
       "FATALITIES       0.010630242 -0.028869204 0.068237339      0.177365053   \n",
       "\n",
       "                  FATALITIES  \n",
       "X               -0.000091933  \n",
       "Y               -0.004291236  \n",
       "PERSONCOUNT      0.047709077  \n",
       "PEDCOUNT         0.073938403  \n",
       "PEDCYLCOUNT      0.010630242  \n",
       "VEHCOUNT        -0.028869204  \n",
       "INJURIES         0.068237339  \n",
       "SERIOUSINJURIES  0.177365053  \n",
       "FATALITIES       1.000000000  \n",
       "\n",
       "[9 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for correlations between variables of type int64 or float64.\n",
    "df_converted.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'Y', 'STATUS', 'ADDRTYPE', 'LOCATION', 'SEVERITYCODE',\n",
       "       'SEVERITYDESC', 'COLLISIONTYPE', 'PERSONCOUNT', 'PEDCOUNT',\n",
       "       'PEDCYLCOUNT', 'VEHCOUNT', 'INJURIES', 'SERIOUSINJURIES', 'FATALITIES',\n",
       "       'INCDATE', 'INCDTTM', 'JUNCTIONTYPE', 'SDOT_COLCODE', 'SDOT_COLDESC',\n",
       "       'UNDERINFL', 'WEATHER', 'ROADCOND', 'LIGHTCOND', 'ST_COLCODE',\n",
       "       'ST_COLDESC', 'HITPARKEDCAR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_converted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_converted[[\"SEVERITYCODE\", \"WEATHER\"]]#list(df_converted.columns)[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROADCOND        SEVERITYDESC                  \n",
       "Dry             Property Damage Only Collision   0.660888207\n",
       "                Injury Collision                 0.319552283\n",
       "                Serious Injury Collision         0.017479907\n",
       "                Fatality Collision               0.002079603\n",
       "Ice             Property Damage Only Collision   0.759932375\n",
       "                Injury Collision                 0.224852071\n",
       "                Serious Injury Collision         0.014370245\n",
       "                Fatality Collision               0.000845309\n",
       "Oil             Property Damage Only Collision   0.591836735\n",
       "                Injury Collision                 0.408163265\n",
       "Other           Property Damage Only Collision   0.647058824\n",
       "                Injury Collision                 0.327731092\n",
       "                Serious Injury Collision         0.025210084\n",
       "Sand/Mud/Dirt   Property Damage Only Collision   0.656250000\n",
       "                Injury Collision                 0.343750000\n",
       "Snow/Slush      Property Damage Only Collision   0.823649337\n",
       "                Injury Collision                 0.168195719\n",
       "                Serious Injury Collision         0.008154944\n",
       "Standing Water  Property Damage Only Collision   0.725490196\n",
       "                Injury Collision                 0.254901961\n",
       "                Serious Injury Collision         0.019607843\n",
       "Unknown         Property Damage Only Collision   0.936462157\n",
       "                Injury Collision                 0.060915924\n",
       "                Serious Injury Collision         0.002534522\n",
       "                Fatality Collision               0.000087397\n",
       "Wet             Property Damage Only Collision   0.652688218\n",
       "                Injury Collision                 0.329931247\n",
       "                Serious Injury Collision         0.015885895\n",
       "                Fatality Collision               0.001473289\n",
       "                Unknown                          0.000021352\n",
       "Name: SEVERITYDESC, Length: 30, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df_converted.groupby([\"ROADCOND\"])[list(df_converted.columns)[6]].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
